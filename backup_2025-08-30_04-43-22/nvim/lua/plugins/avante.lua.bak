return { 
  {
    "yetone/avante.nvim",
    event = "VeryLazy",
    version = false,
    opts = {
      -- debug = true,
      provider = "openai",
      auto_suggestions_provider = nil,
      prviders = {

      -- OpenAI Config 
      openai = {
        endpoint = "https://api.openai.com/v1",
        model = "gpt-4o-mini", -- your desired model (or use gpt-4o, etc.)
        timeout = 30000, -- Timeout in milliseconds, increase this for reasoning models
        temperature = 0,
        max_completion_tokens = 8192, -- Increase this to include reasoning tokens (for reasoning models)
      },

       -- Claude Config
       claude = {
        endpoint = "https://api.anthropic.com",
        model = "claude-sonnet-4-20250514",
        timeout = 30000, -- Timeout in milliseconds
          extra_request_body = {
            temperature = 0.75,
            max_tokens = 20480,
          },
      },
 
     -- Ollama Config
      ollama = {
        model = "qwen3:1.7b",
      },
      }
    },
    build = "make",
    dependencies = {
      "zbirenbaum/copilot.lua", -- Required for copilot provider
      "nvim-treesitter/nvim-treesitter",
      "stevearc/dressing.nvim",
      "nvim-lua/plenary.nvim",
      "MunifTanjim/nui.nvim",
      "hrsh7th/nvim-cmp",
      "nvim-tree/nvim-web-devicons",
      -- Optional:
      "echasnovski/mini.pick",
      "nvim-telescope/telescope.nvim",
      "ibhagwan/fzf-lua",
    },
  }
}
